{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers pandas matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYOwT3vVxbdl",
        "outputId": "27e312bd-3fd5-4239-bed2-79a9f2362818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import pandas as pd\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "# Load the Iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "\n",
        "\n",
        "def query_dataset(query):\n",
        "    \"\"\"\n",
        "    Process a query and retrieve relevant information or visualizations for the Iris dataset.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's query.\n",
        "\n",
        "    Returns:\n",
        "        str: The result of the query or a default message.\n",
        "    \"\"\"\n",
        "    if \"columns\" in query.lower():\n",
        "        return f\"Available columns: {', '.join(iris_df.columns)}\"\n",
        "    elif \"summary\" in query.lower() and \"visualize\" in query.lower():\n",
        "        visualize_summary(iris_df)\n",
        "        return \"Generated a visualization for the dataset summary.\"\n",
        "    elif \"correlation\" in query.lower() and \"visualize\" in query.lower():\n",
        "        visualize_correlation(iris_df)\n",
        "        return \"Generated a correlation heatmap for the dataset.\"\n",
        "    elif \"summary\" in query.lower():\n",
        "        return f\"Dataset summary:\\n{iris_df.describe(include='all')}\"\n",
        "    elif \"correlation\" in query.lower():\n",
        "        return f\"Correlation matrix:\\n{iris_df.iloc[:, :-1].corr()}\"\n",
        "    elif \"rows\" in query.lower():\n",
        "        return f\"The Iris dataset contains {len(iris_df)} rows.\"\n",
        "    elif \"species\" in query.lower():\n",
        "        return f\"Iris species in the dataset: {', '.join(iris.target_names)}\"\n",
        "    return \"I'm not sure how to process that query with the Iris dataset.\"\n",
        "\n",
        "\n",
        "def visualize_summary(data):\n",
        "    \"\"\"\n",
        "    Visualize the summary statistics of the dataset.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The dataset.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(data=data.iloc[:, :-1])  # Exclude the species column for boxplots\n",
        "    plt.title(\"Summary Statistics (Boxplot)\")\n",
        "    plt.xlabel(\"Features\")\n",
        "    plt.ylabel(\"Values\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_correlation(data):\n",
        "    \"\"\"\n",
        "    Visualize the correlation heatmap of the dataset.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The dataset.\n",
        "    \"\"\"\n",
        "    correlation_matrix = data.iloc[:, :-1].corr()  # Exclude the species column\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=True)\n",
        "    plt.title(\"Correlation Heatmap\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def chatbot_response(user_input, chat_history_ids):\n",
        "    \"\"\"\n",
        "    Generate a response from the chatbot given user input and chat history.\n",
        "\n",
        "    Args:\n",
        "        user_input (str): The user's input.\n",
        "        chat_history_ids (torch.Tensor or None): Chat history tensor.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (str, torch.Tensor) The bot's reply and updated chat history.\n",
        "    \"\"\"\n",
        "    # Encode the user input\n",
        "    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # Combine with chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if chat_history_ids is not None else new_user_input_ids\n",
        "\n",
        "    # Generate response\n",
        "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode the response\n",
        "    bot_reply = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return bot_reply, chat_history_ids\n",
        "\n",
        "\n",
        "# Chat loop\n",
        "chat_history_ids = None\n",
        "\n",
        "print(\"Chatbot is ready! Type 'exit' or 'quit' to end the chat.\")\n",
        "\n",
        "for step in range(5):\n",
        "    user_input = input(\">> User: \")\n",
        "\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"DialoGPT: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Check if user input relates to the dataset\n",
        "    if any(keyword in user_input.lower() for keyword in [\"iris\", \"dataset\", \"visualize\", \"summary\", \"correlation\", \"rows\", \"species\"]):\n",
        "        result = query_dataset(user_input)\n",
        "        print(f\"DialoGPT: {result}\")\n",
        "    else:\n",
        "        # Generate chatbot response\n",
        "        bot_reply, chat_history_ids = chatbot_response(user_input, chat_history_ids)\n",
        "        print(f\"DialoGPT: {bot_reply}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOpmuCkkQzOQ",
        "outputId": "36a2b818-12fa-41d8-98eb-e90b358b5670"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot is ready! Type 'exit' or 'quit' to end the chat.\n",
            ">> User: visualize\n",
            "DialoGPT: I'm not sure how to process that query with the Iris dataset.\n",
            ">> User: summary\n",
            "DialoGPT: Dataset summary:\n",
            "        sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
            "count          150.000000        150.000000         150.000000   \n",
            "unique                NaN               NaN                NaN   \n",
            "top                   NaN               NaN                NaN   \n",
            "freq                  NaN               NaN                NaN   \n",
            "mean             5.843333          3.057333           3.758000   \n",
            "std              0.828066          0.435866           1.765298   \n",
            "min              4.300000          2.000000           1.000000   \n",
            "25%              5.100000          2.800000           1.600000   \n",
            "50%              5.800000          3.000000           4.350000   \n",
            "75%              6.400000          3.300000           5.100000   \n",
            "max              7.900000          4.400000           6.900000   \n",
            "\n",
            "        petal width (cm) species  \n",
            "count         150.000000     150  \n",
            "unique               NaN       3  \n",
            "top                  NaN  setosa  \n",
            "freq                 NaN      50  \n",
            "mean            1.199333     NaN  \n",
            "std             0.762238     NaN  \n",
            "min             0.100000     NaN  \n",
            "25%             0.300000     NaN  \n",
            "50%             1.300000     NaN  \n",
            "75%             1.800000     NaN  \n",
            "max             2.500000     NaN  \n",
            ">> User: correlation\n",
            "DialoGPT: Correlation matrix:\n",
            "                   sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
            "sepal length (cm)           1.000000         -0.117570           0.871754   \n",
            "sepal width (cm)           -0.117570          1.000000          -0.428440   \n",
            "petal length (cm)           0.871754         -0.428440           1.000000   \n",
            "petal width (cm)            0.817941         -0.366126           0.962865   \n",
            "\n",
            "                   petal width (cm)  \n",
            "sepal length (cm)          0.817941  \n",
            "sepal width (cm)          -0.366126  \n",
            "petal length (cm)          0.962865  \n",
            "petal width (cm)           1.000000  \n",
            ">> User: visualize\n",
            "DialoGPT: I'm not sure how to process that query with the Iris dataset.\n",
            ">> User: species\n",
            "DialoGPT: Iris species in the dataset: setosa, versicolor, virginica\n"
          ]
        }
      ]
    }
  ]
}